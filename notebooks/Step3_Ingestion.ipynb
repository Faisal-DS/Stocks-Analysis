{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3abd04e7-5716-41ff-a643-cd58890a0515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\engr_\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Packages imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install required packages (safe to re-run)\n",
    "%pip -q install requests pymongo python-dotenv\n",
    "\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient, UpdateOne\n",
    "\n",
    "print(\"Packages imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb05d66-e6b9-4aa2-9ce8-3085d6134c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for .env at: C:\\Users\\engr_\\Stocks-Analysis\\.env\n",
      "API_KEY loaded: True\n",
      "MONGO_URI loaded: True\n",
      "MONGO_URI preview: cluster0.kkkaco7.mongodb.net/?appName=Cl...\n",
      "Estimated docs in raw_prices: 0\n",
      "Connected to MongoDB successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "\n",
    "env_path = os.path.join(os.getcwd(), \".env\")\n",
    "print(\"Looking for .env at:\", env_path)\n",
    "\n",
    "load_dotenv(env_path)\n",
    "\n",
    "API_KEY = os.getenv(\"ALPHA_VANTAGE_API_KEY\")\n",
    "MONGO_URI = os.getenv(\"MONGODB_URI\")\n",
    "\n",
    "print(\"API_KEY loaded:\", API_KEY is not None)\n",
    "print(\"MONGO_URI loaded:\", MONGO_URI is not None)\n",
    "\n",
    "# Print a safe preview (no secrets) to confirm format\n",
    "if MONGO_URI:\n",
    "    print(\"MONGO_URI preview:\", MONGO_URI.split(\"@\")[-1][:40] + \"...\")\n",
    "\n",
    "assert API_KEY is not None, \"ALPHA_VANTAGE_API_KEY not found in .env\"\n",
    "assert MONGO_URI is not None, \"MONGODB_URI not found in .env\"\n",
    "\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[\"stocks\"]\n",
    "collection = db[\"raw_prices\"]\n",
    "\n",
    "print(\"Estimated docs in raw_prices:\", collection.estimated_document_count())\n",
    "print(\"Connected to MongoDB successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c357237-311f-4bfa-9ab3-c4c1ac815916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta keys: ['1. Information', '2. Symbol', '3. Last Refreshed', '4. Output Size', '5. Time Zone']\n",
      "Daily rows returned: 100\n",
      "Sample date: 2025-12-26 Sample close: 273.4000\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_daily_free(symbol: str, api_key: str) -> dict:\n",
    "    url = (\n",
    "        \"https://www.alphavantage.co/query\"\n",
    "        f\"?function=TIME_SERIES_DAILY\"\n",
    "        f\"&symbol={symbol}\"\n",
    "        f\"&outputsize=compact\"\n",
    "        f\"&apikey={api_key}\"\n",
    "    )\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "payload = fetch_daily_free(\"AAPL\", API_KEY)\n",
    "\n",
    "if \"Error Message\" in payload:\n",
    "    print(\"ERROR:\", payload[\"Error Message\"])\n",
    "elif \"Note\" in payload:\n",
    "    print(\"RATE LIMIT NOTE:\", payload[\"Note\"])\n",
    "elif \"Information\" in payload:\n",
    "    print(\"INFO:\", payload[\"Information\"])\n",
    "else:\n",
    "    meta = payload.get(\"Meta Data\", {})\n",
    "    ts = payload.get(\"Time Series (Daily)\", {})\n",
    "    print(\"Meta keys:\", list(meta.keys()))\n",
    "    print(\"Daily rows returned:\", len(ts))\n",
    "    if ts:\n",
    "        first_date = next(iter(ts.keys()))\n",
    "        print(\"Sample date:\", first_date, \"Sample close:\", ts[first_date].get(\"4. close\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f04ef6f-ba07-458a-81bc-19c170ec1f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: ['01. symbol', '02. open', '03. high', '04. low', '05. price', '06. volume', '07. latest trading day', '08. previous close', '09. change', '10. change percent']\n",
      "Symbol: AAPL\n",
      "Price: 273.4000\n",
      "Volume: 21521802\n",
      "Latest trading day: 2025-12-26\n",
      "Pulled at (UTC): 2025-12-27T12:41:58.812823+00:00\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def fetch_global_quote(symbol: str, api_key: str) -> dict:\n",
    "    url = (\n",
    "        \"https://www.alphavantage.co/query\"\n",
    "        f\"?function=GLOBAL_QUOTE\"\n",
    "        f\"&symbol={symbol}\"\n",
    "        f\"&apikey={api_key}\"\n",
    "    )\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "q = fetch_global_quote(\"AAPL\", API_KEY)\n",
    "\n",
    "if \"Error Message\" in q:\n",
    "    print(\"ERROR:\", q[\"Error Message\"])\n",
    "elif \"Note\" in q:\n",
    "    print(\"RATE LIMIT NOTE:\", q[\"Note\"])\n",
    "elif \"Information\" in q:\n",
    "    print(\"INFO:\", q[\"Information\"])\n",
    "else:\n",
    "    quote = q.get(\"Global Quote\", {})\n",
    "    print(\"Keys:\", list(quote.keys()))\n",
    "    print(\"Symbol:\", quote.get(\"01. symbol\"))\n",
    "    print(\"Price:\", quote.get(\"05. price\"))\n",
    "    print(\"Volume:\", quote.get(\"06. volume\"))\n",
    "    print(\"Latest trading day:\", quote.get(\"07. latest trading day\"))\n",
    "    print(\"Pulled at (UTC):\", datetime.now(timezone.utc).isoformat())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ff2976e-30cf-4475-b838-1502e5595d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored quote snapshot for AAPL\n",
      "raw_prices total docs now: 1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Use correct DB name casing\n",
    "db = client[\"Stocks\"]\n",
    "collection = db[\"raw_prices\"]\n",
    "\n",
    "def quote_to_doc(payload: dict, pulled_at_utc: datetime) -> dict:\n",
    "    q = payload.get(\"Global Quote\", {})\n",
    "    ts = pulled_at_utc.astimezone(timezone.utc).replace(tzinfo=None)\n",
    "\n",
    "    def val(k, default=None):\n",
    "        v = q.get(k)\n",
    "        return default if v in (None, \"\") else v\n",
    "\n",
    "    return {\n",
    "        \"symbol\": val(\"01. symbol\"),\n",
    "        \"timestamp\": ts,\n",
    "        \"interval\": \"quote\",\n",
    "        \"open\": float(val(\"02. open\", 0.0)),\n",
    "        \"high\": float(val(\"03. high\", 0.0)),\n",
    "        \"low\": float(val(\"04. low\", 0.0)),\n",
    "        \"close\": float(val(\"05. price\", 0.0)),\n",
    "        \"volume\": int(float(val(\"06. volume\", 0))),\n",
    "        \"latest_trading_day\": val(\"07. latest trading day\"),\n",
    "        \"prev_close\": float(val(\"08. previous close\", 0.0)),\n",
    "        \"change\": float(val(\"09. change\", 0.0)),\n",
    "        \"change_percent\": val(\"10. change percent\"),\n",
    "        \"source\": \"alpha_vantage\",\n",
    "        \"ingested_at\": datetime.now(timezone.utc).replace(tzinfo=None)\n",
    "    }\n",
    "\n",
    "pulled_at = datetime.now(timezone.utc)\n",
    "doc = quote_to_doc(q, pulled_at)\n",
    "\n",
    "assert doc[\"symbol\"], \"Quote parsing failed: symbol missing\"\n",
    "\n",
    "collection.update_one(\n",
    "    {\"symbol\": doc[\"symbol\"], \"timestamp\": doc[\"timestamp\"], \"interval\": doc[\"interval\"]},\n",
    "    {\"$set\": doc},\n",
    "    upsert=True\n",
    ")\n",
    "\n",
    "print(\"Stored quote snapshot for\", doc[\"symbol\"])\n",
    "print(\"raw_prices total docs now:\", collection.estimated_document_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "174a3595-50e0-41b1-b451-46916576448d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DAILY BACKFILL (compact) for AAPL ===\n",
      "Rows fetched: 100, upserted: 100\n",
      "\n",
      "=== DAILY BACKFILL (compact) for MSFT ===\n",
      "Rows fetched: 100, upserted: 100\n",
      "\n",
      "=== DAILY BACKFILL (compact) for NVDA ===\n",
      "Rows fetched: 100, upserted: 100\n",
      "\n",
      "=== DAILY BACKFILL (compact) for AMZN ===\n",
      "Rows fetched: 100, upserted: 100\n",
      "\n",
      "=== DAILY BACKFILL (compact) for TSLA ===\n",
      "Rows fetched: 100, upserted: 100\n",
      "\n",
      "=== DAILY BACKFILL (compact) for APP ===\n",
      "Rows fetched: 100, upserted: 100\n",
      "\n",
      "=== DAILY BACKFILL (compact) for SMCI ===\n",
      "Rows fetched: 100, upserted: 100\n",
      "\n",
      "=== DAILY BACKFILL (compact) for SPY ===\n",
      "Rows fetched: 100, upserted: 100\n",
      "\n",
      "TOTAL upserted in this run: 800\n",
      "raw_prices total docs now: 801\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "from pymongo import UpdateOne\n",
    "\n",
    "SYMBOLS = [\"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"TSLA\", \"APP\", \"SMCI\", \"SPY\"]\n",
    "\n",
    "def fetch_daily_free(symbol: str, api_key: str, outputsize: str = \"compact\") -> dict:\n",
    "    url = (\n",
    "        \"https://www.alphavantage.co/query\"\n",
    "        f\"?function=TIME_SERIES_DAILY\"\n",
    "        f\"&symbol={symbol}\"\n",
    "        f\"&outputsize={outputsize}\"\n",
    "        f\"&apikey={api_key}\"\n",
    "    )\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def parse_daily_docs(symbol: str, payload: dict) -> list[dict]:\n",
    "    ts = payload.get(\"Time Series (Daily)\", {})\n",
    "    docs = []\n",
    "    for date_str, v in ts.items():\n",
    "        docs.append({\n",
    "            \"symbol\": symbol,\n",
    "            \"timestamp\": datetime.fromisoformat(date_str),  # date only\n",
    "            \"interval\": \"1day\",\n",
    "            \"open\": float(v[\"1. open\"]),\n",
    "            \"high\": float(v[\"2. high\"]),\n",
    "            \"low\": float(v[\"3. low\"]),\n",
    "            \"close\": float(v[\"4. close\"]),\n",
    "            \"volume\": int(float(v[\"5. volume\"])),\n",
    "            \"source\": \"alpha_vantage\",\n",
    "            \"ingested_at\": datetime.now(timezone.utc).replace(tzinfo=None)\n",
    "        })\n",
    "    return docs\n",
    "\n",
    "def upsert_many(docs: list[dict]) -> int:\n",
    "    if not docs:\n",
    "        return 0\n",
    "    ops = [\n",
    "        UpdateOne(\n",
    "            {\"symbol\": d[\"symbol\"], \"timestamp\": d[\"timestamp\"], \"interval\": d[\"interval\"]},\n",
    "            {\"$set\": d},\n",
    "            upsert=True\n",
    "        )\n",
    "        for d in docs\n",
    "    ]\n",
    "    result = collection.bulk_write(ops, ordered=False)\n",
    "    return (result.upserted_count or 0) + (result.modified_count or 0)\n",
    "\n",
    "total_written = 0\n",
    "\n",
    "for sym in SYMBOLS:\n",
    "    print(f\"\\n=== DAILY BACKFILL (compact) for {sym} ===\")\n",
    "    payload = fetch_daily_free(sym, API_KEY, outputsize=\"compact\")\n",
    "\n",
    "    if \"Note\" in payload:\n",
    "        print(\"RATE LIMIT NOTE:\", payload[\"Note\"])\n",
    "        print(\"Stopping here. Wait 60 seconds and rerun this cell.\")\n",
    "        break\n",
    "    if \"Error Message\" in payload:\n",
    "        print(\"ERROR:\", payload[\"Error Message\"])\n",
    "        continue\n",
    "    if \"Information\" in payload:\n",
    "        print(\"INFO:\", payload[\"Information\"])\n",
    "        continue\n",
    "\n",
    "    docs = parse_daily_docs(sym, payload)\n",
    "    written = upsert_many(docs)\n",
    "    total_written += written\n",
    "\n",
    "    print(f\"Rows fetched: {len(docs)}, upserted: {written}\")\n",
    "    time.sleep(15)  # stay under free tier limits\n",
    "\n",
    "print(\"\\nTOTAL upserted in this run:\", total_written)\n",
    "print(\"raw_prices total docs now:\", collection.estimated_document_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf868337-97fc-4bac-a77c-3d12c0dfc345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff date (keep >=): 2022-12-28\n",
      "\n",
      "=== DAILY BACKFILL (full, last 3y) for AAPL ===\n",
      "INFO: Thank you for using Alpha Vantage! The outputsize=full parameter value is a premium feature for the TIME_SERIES_DAILY endpoint. You may subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly unlock all premium features\n",
      "\n",
      "=== DAILY BACKFILL (full, last 3y) for MSFT ===\n",
      "INFO: Thank you for using Alpha Vantage! The outputsize=full parameter value is a premium feature for the TIME_SERIES_DAILY endpoint. You may subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly unlock all premium features\n",
      "\n",
      "=== DAILY BACKFILL (full, last 3y) for NVDA ===\n",
      "INFO: Thank you for using Alpha Vantage! The outputsize=full parameter value is a premium feature for the TIME_SERIES_DAILY endpoint. You may subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly unlock all premium features\n",
      "\n",
      "=== DAILY BACKFILL (full, last 3y) for AMZN ===\n",
      "INFO: Thank you for using Alpha Vantage! The outputsize=full parameter value is a premium feature for the TIME_SERIES_DAILY endpoint. You may subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly unlock all premium features\n",
      "\n",
      "=== DAILY BACKFILL (full, last 3y) for TSLA ===\n",
      "INFO: Thank you for using Alpha Vantage! The outputsize=full parameter value is a premium feature for the TIME_SERIES_DAILY endpoint. You may subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly unlock all premium features\n",
      "\n",
      "=== DAILY BACKFILL (full, last 3y) for APP ===\n",
      "INFO: Thank you for using Alpha Vantage! The outputsize=full parameter value is a premium feature for the TIME_SERIES_DAILY endpoint. You may subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly unlock all premium features\n",
      "\n",
      "=== DAILY BACKFILL (full, last 3y) for SMCI ===\n",
      "INFO: Thank you for using Alpha Vantage! The outputsize=full parameter value is a premium feature for the TIME_SERIES_DAILY endpoint. You may subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly unlock all premium features\n",
      "\n",
      "=== DAILY BACKFILL (full, last 3y) for SPY ===\n",
      "INFO: Thank you for using Alpha Vantage! The outputsize=full parameter value is a premium feature for the TIME_SERIES_DAILY endpoint. You may subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly unlock all premium features\n",
      "\n",
      "TOTAL upserted in this run: 0\n",
      "raw_prices total docs now: 801\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "from datetime import datetime, date, timedelta, timezone\n",
    "from pymongo import UpdateOne\n",
    "\n",
    "SYMBOLS = [\"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"TSLA\", \"APP\", \"SMCI\", \"SPY\"]\n",
    "\n",
    "# Keep last 3 years (approx). You can tighten later if needed.\n",
    "cutoff_date = date.today() - timedelta(days=365*3)\n",
    "print(\"Cutoff date (keep >=):\", cutoff_date)\n",
    "\n",
    "def fetch_daily_free(symbol: str, api_key: str, outputsize: str = \"full\") -> dict:\n",
    "    url = (\n",
    "        \"https://www.alphavantage.co/query\"\n",
    "        f\"?function=TIME_SERIES_DAILY\"\n",
    "        f\"&symbol={symbol}\"\n",
    "        f\"&outputsize={outputsize}\"\n",
    "        f\"&apikey={api_key}\"\n",
    "    )\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def parse_daily_docs_3y(symbol: str, payload: dict, cutoff: date) -> list[dict]:\n",
    "    ts = payload.get(\"Time Series (Daily)\", {})\n",
    "    docs = []\n",
    "    for date_str, v in ts.items():\n",
    "        d = date.fromisoformat(date_str)\n",
    "        if d < cutoff:\n",
    "            continue\n",
    "        docs.append({\n",
    "            \"symbol\": symbol,\n",
    "            \"timestamp\": datetime.fromisoformat(date_str),\n",
    "            \"interval\": \"1day\",\n",
    "            \"open\": float(v[\"1. open\"]),\n",
    "            \"high\": float(v[\"2. high\"]),\n",
    "            \"low\": float(v[\"3. low\"]),\n",
    "            \"close\": float(v[\"4. close\"]),\n",
    "            \"volume\": int(float(v[\"5. volume\"])),\n",
    "            \"source\": \"alpha_vantage\",\n",
    "            \"ingested_at\": datetime.now(timezone.utc).replace(tzinfo=None)\n",
    "        })\n",
    "    return docs\n",
    "\n",
    "def upsert_many(docs: list[dict]) -> int:\n",
    "    if not docs:\n",
    "        return 0\n",
    "    ops = [\n",
    "        UpdateOne(\n",
    "            {\"symbol\": d[\"symbol\"], \"timestamp\": d[\"timestamp\"], \"interval\": d[\"interval\"]},\n",
    "            {\"$set\": d},\n",
    "            upsert=True\n",
    "        )\n",
    "        for d in docs\n",
    "    ]\n",
    "    result = collection.bulk_write(ops, ordered=False)\n",
    "    return (result.upserted_count or 0) + (result.modified_count or 0)\n",
    "\n",
    "total_written = 0\n",
    "\n",
    "for sym in SYMBOLS:\n",
    "    print(f\"\\n=== DAILY BACKFILL (full, last 3y) for {sym} ===\")\n",
    "    payload = fetch_daily_free(sym, API_KEY, outputsize=\"full\")\n",
    "\n",
    "    if \"Note\" in payload:\n",
    "        print(\"RATE LIMIT NOTE:\", payload[\"Note\"])\n",
    "        print(\"Stop here. Wait 60 seconds and rerun this cell.\")\n",
    "        break\n",
    "    if \"Error Message\" in payload:\n",
    "        print(\"ERROR:\", payload[\"Error Message\"])\n",
    "        continue\n",
    "    if \"Information\" in payload:\n",
    "        print(\"INFO:\", payload[\"Information\"])\n",
    "        continue\n",
    "\n",
    "    docs = parse_daily_docs_3y(sym, payload, cutoff_date)\n",
    "    written = upsert_many(docs)\n",
    "    total_written += written\n",
    "\n",
    "    print(f\"Rows kept (>= cutoff): {len(docs)}, upserted: {written}\")\n",
    "    time.sleep(15)\n",
    "\n",
    "print(\"\\nTOTAL upserted in this run:\", total_written)\n",
    "print(\"raw_prices total docs now:\", collection.estimated_document_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd41e927-4c32-4ce7-9aee-a37a73dfe640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff date (keep >=): 2022-12-28\n",
      "Rows parsed (>= cutoff): 752\n",
      "Upserted: 752\n",
      "raw_prices total docs now: 1453\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import io\n",
    "import requests\n",
    "from datetime import datetime, date, timedelta, timezone\n",
    "from pymongo import UpdateOne\n",
    "\n",
    "cutoff_date = date.today() - timedelta(days=365*3)\n",
    "print(\"Cutoff date (keep >=):\", cutoff_date)\n",
    "\n",
    "def stooq_symbol(sym: str) -> str:\n",
    "    # Stooq uses lower-case and \".us\" for US equities/ETFs\n",
    "    return sym.lower() + \".us\"\n",
    "\n",
    "def fetch_stooq_daily_csv(sym: str) -> str:\n",
    "    s = stooq_symbol(sym)\n",
    "    url = f\"https://stooq.com/q/d/l/?s={s}&i=d\"\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "def parse_stooq_csv(sym: str, csv_text: str, cutoff: date) -> list[dict]:\n",
    "    reader = csv.DictReader(io.StringIO(csv_text))\n",
    "    docs = []\n",
    "    for row in reader:\n",
    "        # Row keys: Date, Open, High, Low, Close, Volume\n",
    "        d = date.fromisoformat(row[\"Date\"])\n",
    "        if d < cutoff:\n",
    "            continue\n",
    "        docs.append({\n",
    "            \"symbol\": sym,\n",
    "            \"timestamp\": datetime.fromisoformat(row[\"Date\"]),\n",
    "            \"interval\": \"1day\",\n",
    "            \"open\": float(row[\"Open\"]),\n",
    "            \"high\": float(row[\"High\"]),\n",
    "            \"low\": float(row[\"Low\"]),\n",
    "            \"close\": float(row[\"Close\"]),\n",
    "            \"volume\": int(float(row[\"Volume\"])),\n",
    "            \"source\": \"stooq\",\n",
    "            \"ingested_at\": datetime.now(timezone.utc).replace(tzinfo=None)\n",
    "        })\n",
    "    return docs\n",
    "\n",
    "def upsert_many(docs: list[dict]) -> int:\n",
    "    if not docs:\n",
    "        return 0\n",
    "    ops = [\n",
    "        UpdateOne(\n",
    "            {\"symbol\": d[\"symbol\"], \"timestamp\": d[\"timestamp\"], \"interval\": d[\"interval\"]},\n",
    "            {\"$set\": d},\n",
    "            upsert=True\n",
    "        )\n",
    "        for d in docs\n",
    "    ]\n",
    "    result = collection.bulk_write(ops, ordered=False)\n",
    "    return (result.upserted_count or 0) + (result.modified_count or 0)\n",
    "\n",
    "# Test with ONE symbol first\n",
    "sym = \"AAPL\"\n",
    "csv_text = fetch_stooq_daily_csv(sym)\n",
    "docs = parse_stooq_csv(sym, csv_text, cutoff_date)\n",
    "\n",
    "print(\"Rows parsed (>= cutoff):\", len(docs))\n",
    "written = upsert_many(docs)\n",
    "print(\"Upserted:\", written)\n",
    "print(\"raw_prices total docs now:\", collection.estimated_document_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82e16ef4-38aa-49d5-a853-2045585896d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff date (keep >=): 2022-12-28\n",
      "\n",
      "=== STOOQ DAILY (last 3y) for AAPL ===\n",
      "Rows parsed: 752\n",
      "Upserted: 752\n",
      "\n",
      "=== STOOQ DAILY (last 3y) for MSFT ===\n",
      "Rows parsed: 752\n",
      "Upserted: 752\n",
      "\n",
      "=== STOOQ DAILY (last 3y) for NVDA ===\n",
      "Rows parsed: 752\n",
      "Upserted: 752\n",
      "\n",
      "=== STOOQ DAILY (last 3y) for AMZN ===\n",
      "Rows parsed: 752\n",
      "Upserted: 752\n",
      "\n",
      "=== STOOQ DAILY (last 3y) for TSLA ===\n",
      "Rows parsed: 752\n",
      "Upserted: 752\n",
      "\n",
      "=== STOOQ DAILY (last 3y) for APP ===\n",
      "Rows parsed: 752\n",
      "Upserted: 752\n",
      "\n",
      "=== STOOQ DAILY (last 3y) for SMCI ===\n",
      "Rows parsed: 752\n",
      "Upserted: 752\n",
      "\n",
      "=== STOOQ DAILY (last 3y) for SPY ===\n",
      "Rows parsed: 752\n",
      "Upserted: 752\n",
      "\n",
      "TOTAL upserted this run: 6016\n",
      "raw_prices total docs now: 6017\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import io\n",
    "import requests\n",
    "from datetime import datetime, date, timedelta, timezone\n",
    "from pymongo import UpdateOne\n",
    "\n",
    "SYMBOLS = [\"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"TSLA\", \"APP\", \"SMCI\", \"SPY\"]\n",
    "\n",
    "cutoff_date = date.today() - timedelta(days=365*3)\n",
    "print(\"Cutoff date (keep >=):\", cutoff_date)\n",
    "\n",
    "def stooq_symbol(sym: str) -> str:\n",
    "    return sym.lower() + \".us\"\n",
    "\n",
    "def fetch_stooq_daily_csv(sym: str) -> str:\n",
    "    url = f\"https://stooq.com/q/d/l/?s={stooq_symbol(sym)}&i=d\"\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "def parse_stooq_csv(sym: str, csv_text: str, cutoff: date) -> list[dict]:\n",
    "    reader = csv.DictReader(io.StringIO(csv_text))\n",
    "    docs = []\n",
    "    for row in reader:\n",
    "        d = date.fromisoformat(row[\"Date\"])\n",
    "        if d < cutoff:\n",
    "            continue\n",
    "        docs.append({\n",
    "            \"symbol\": sym,\n",
    "            \"timestamp\": datetime.fromisoformat(row[\"Date\"]),\n",
    "            \"interval\": \"1day\",\n",
    "            \"open\": float(row[\"Open\"]),\n",
    "            \"high\": float(row[\"High\"]),\n",
    "            \"low\": float(row[\"Low\"]),\n",
    "            \"close\": float(row[\"Close\"]),\n",
    "            \"volume\": int(float(row[\"Volume\"])),\n",
    "            \"source\": \"stooq\",\n",
    "            \"ingested_at\": datetime.now(timezone.utc).replace(tzinfo=None)\n",
    "        })\n",
    "    return docs\n",
    "\n",
    "def upsert_many(docs: list[dict]) -> int:\n",
    "    if not docs:\n",
    "        return 0\n",
    "    ops = [\n",
    "        UpdateOne(\n",
    "            {\"symbol\": d[\"symbol\"], \"timestamp\": d[\"timestamp\"], \"interval\": d[\"interval\"]},\n",
    "            {\"$set\": d},\n",
    "            upsert=True\n",
    "        )\n",
    "        for d in docs\n",
    "    ]\n",
    "    result = collection.bulk_write(ops, ordered=False)\n",
    "    return (result.upserted_count or 0) + (result.modified_count or 0)\n",
    "\n",
    "total_upserted = 0\n",
    "\n",
    "for sym in SYMBOLS:\n",
    "    print(f\"\\n=== STOOQ DAILY (last 3y) for {sym} ===\")\n",
    "    try:\n",
    "        csv_text = fetch_stooq_daily_csv(sym)\n",
    "        docs = parse_stooq_csv(sym, csv_text, cutoff_date)\n",
    "        print(\"Rows parsed:\", len(docs))\n",
    "        written = upsert_many(docs)\n",
    "        total_upserted += written\n",
    "        print(\"Upserted:\", written)\n",
    "    except Exception as e:\n",
    "        print(\"FAILED:\", sym, \"|\", repr(e))\n",
    "\n",
    "print(\"\\nTOTAL upserted this run:\", total_upserted)\n",
    "print(\"raw_prices total docs now:\", collection.estimated_document_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45297098-8f2e-4188-952e-be8088bba017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting quote polling loop. Stop with Kernel -> Interrupt.\n",
      "Stored quote: AAPL | ts: 2025-12-27 13:43:11.990559\n",
      "Stored quote: MSFT | ts: 2025-12-27 13:43:28.591844\n",
      "Stored quote: NVDA | ts: 2025-12-27 13:43:44.879372\n",
      "Stored quote: AMZN | ts: 2025-12-27 13:44:01.259338\n",
      "Stored quote: TSLA | ts: 2025-12-27 13:44:17.750039\n",
      "Stored quote: APP | ts: 2025-12-27 13:44:34.335342\n",
      "Stored quote: SMCI | ts: 2025-12-27 13:44:51.027867\n",
      "Stored quote: SPY | ts: 2025-12-27 13:45:07.308955\n",
      "Cycle complete: 8/8 stored. UTC: 2025-12-27T13:43:11.990559+00:00\n",
      "Sleeping 300 seconds...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 82\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCycle complete: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mok\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(SYMBOLS)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m stored. UTC:\u001b[39m\u001b[33m\"\u001b[39m, start.isoformat())\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSleeping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPOLL_SECONDS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPOLL_SECONDS\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "SYMBOLS = [\"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"TSLA\", \"APP\", \"SMCI\", \"SPY\"]\n",
    "POLL_SECONDS = 300  # 5 minutes\n",
    "\n",
    "def fetch_global_quote(symbol: str, api_key: str) -> dict:\n",
    "    url = (\n",
    "        \"https://www.alphavantage.co/query\"\n",
    "        f\"?function=GLOBAL_QUOTE\"\n",
    "        f\"&symbol={symbol}\"\n",
    "        f\"&apikey={api_key}\"\n",
    "    )\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def quote_to_doc(payload: dict, pulled_at_utc: datetime) -> dict:\n",
    "    q = payload.get(\"Global Quote\", {})\n",
    "    ts = pulled_at_utc.astimezone(timezone.utc).replace(tzinfo=None)\n",
    "\n",
    "    def val(k, default=None):\n",
    "        v = q.get(k)\n",
    "        return default if v in (None, \"\") else v\n",
    "\n",
    "    return {\n",
    "        \"symbol\": val(\"01. symbol\"),\n",
    "        \"timestamp\": ts,\n",
    "        \"interval\": \"quote\",\n",
    "        \"open\": float(val(\"02. open\", 0.0)),\n",
    "        \"high\": float(val(\"03. high\", 0.0)),\n",
    "        \"low\": float(val(\"04. low\", 0.0)),\n",
    "        \"close\": float(val(\"05. price\", 0.0)),\n",
    "        \"volume\": int(float(val(\"06. volume\", 0))),\n",
    "        \"latest_trading_day\": val(\"07. latest trading day\"),\n",
    "        \"prev_close\": float(val(\"08. previous close\", 0.0)),\n",
    "        \"change\": float(val(\"09. change\", 0.0)),\n",
    "        \"change_percent\": val(\"10. change percent\"),\n",
    "        \"source\": \"alpha_vantage\",\n",
    "        \"ingested_at\": datetime.now(timezone.utc).replace(tzinfo=None)\n",
    "    }\n",
    "\n",
    "def store_quote_snapshot(symbol: str):\n",
    "    pulled_at = datetime.now(timezone.utc)\n",
    "    payload = fetch_global_quote(symbol, API_KEY)\n",
    "\n",
    "    if \"Note\" in payload:\n",
    "        print(\"RATE LIMIT NOTE:\", payload[\"Note\"])\n",
    "        return False\n",
    "    if \"Error Message\" in payload:\n",
    "        print(\"ERROR:\", symbol, payload[\"Error Message\"])\n",
    "        return False\n",
    "    if \"Information\" in payload:\n",
    "        print(\"INFO:\", symbol, payload[\"Information\"])\n",
    "        return False\n",
    "\n",
    "    doc = quote_to_doc(payload, pulled_at)\n",
    "    if not doc.get(\"symbol\"):\n",
    "        print(\"Parse failed for\", symbol)\n",
    "        return False\n",
    "\n",
    "    collection.update_one(\n",
    "        {\"symbol\": doc[\"symbol\"], \"timestamp\": doc[\"timestamp\"], \"interval\": doc[\"interval\"]},\n",
    "        {\"$set\": doc},\n",
    "        upsert=True\n",
    "    )\n",
    "    print(\"Stored quote:\", symbol, \"| ts:\", doc[\"timestamp\"])\n",
    "    return True\n",
    "\n",
    "print(\"Starting quote polling loop. Stop with Kernel -> Interrupt.\")\n",
    "while True:\n",
    "    start = datetime.now(timezone.utc)\n",
    "    ok = 0\n",
    "    for sym in SYMBOLS:\n",
    "        if store_quote_snapshot(sym):\n",
    "            ok += 1\n",
    "        time.sleep(15)  # spacing calls to reduce throttling risk\n",
    "\n",
    "    print(f\"Cycle complete: {ok}/{len(SYMBOLS)} stored. UTC:\", start.isoformat())\n",
    "    print(f\"Sleeping {POLL_SECONDS} seconds...\\n\")\n",
    "    time.sleep(POLL_SECONDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9813f46c-4188-48b4-8194-a2d4b80b4453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
